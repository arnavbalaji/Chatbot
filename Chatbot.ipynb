{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TWXQB0kSfaW",
    "outputId": "3f0f545b-b415-407d-c1fa-e1313ba88ff0"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext==0.10.0 pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cp9sq3aSfaY",
    "outputId": "77f01b2a-bdd3-4ee3-be00-e204b0324fb7"
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkswuXxySfaY",
    "outputId": "9499f712-4716-41ca-d558-14eed8759d7a"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WCZTABdISfaZ"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "#from torchtext.legacy.data import Iterator\n",
    "#from torchtext.legacy.data import Example\n",
    "#from torchtext.legacy.data import Field\n",
    "from torchtext.datasets import SQuAD2\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "favo0BkrSfaZ"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = SQuAD2(split=('train', 'dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DjqsQdZ0SfaZ"
   },
   "outputs": [],
   "source": [
    "train_dictionary = {\"Questions\" : [], \"Answers\": []}\n",
    "for _, q, a, _ in train_data:\n",
    "    train_dictionary[\"Questions\"].append(q)\n",
    "    train_dictionary[\"Answers\"].append(a[0])\n",
    "train_df = pd.DataFrame(train_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "klHuWP4sSfaa"
   },
   "outputs": [],
   "source": [
    "val_dictionary = {\"Questions\" : [], \"Answers\": []}\n",
    "for _, q, a, _ in val_data:\n",
    "    val_dictionary[\"Questions\"].append(q)\n",
    "    val_dictionary[\"Answers\"].append(a[0])\n",
    "val_df = pd.DataFrame(val_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0u2JKVF4Sfaa",
    "outputId": "3a0fe0d3-8dca-4d1e-c65c-824b7283b784"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions              Answers\n",
       "0           When did Beyonce start becoming popular?    in the late 1990s\n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing\n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003\n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas\n",
       "4         In which decade did Beyonce become famous?           late 1990s"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1rlA5WJ-Sfaa",
    "outputId": "9bfcfa1d-4ed1-4551-f954-f3422492c629"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "      <td>10th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0               In what country is Normandy located?   \n",
       "1                 When were the Normans in Normandy?   \n",
       "2      From which countries did the Norse originate?   \n",
       "3                          Who was the Norse leader?   \n",
       "4  What century did the Normans first gain their ...   \n",
       "\n",
       "                       Answers  \n",
       "0                       France  \n",
       "1      10th and 11th centuries  \n",
       "2  Denmark, Iceland and Norway  \n",
       "3                        Rollo  \n",
       "4                 10th century  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3p5c993ySfaa"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"EOW\" : 0, \"EOS\": 1}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"EOW\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            if (word != \"EOW\"):\n",
    "              self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YD2Q41bjSfab"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    tokens = ' '.join([token.text for token in nlp(sentence)])\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def prepare_data(data_df):\n",
    "    data_df['Questions'] = data_df['Questions'].apply(prepare_text)\n",
    "    data_df['Answers'] = data_df['Answers'].apply(prepare_text)\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "By1HoAQNSfab",
    "outputId": "483d76ff-aab7-49cf-e672-c5c0ad891404"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_data(train_df.iloc[:100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUZWmqObAs9f",
    "outputId": "6cc97f89-8103-4a90-8686-5d3a15c90a28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "x7a4pq5JBGvt",
    "outputId": "4c70c0f5-b3ef-491b-a955-28a0c53ff71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the late 1990s'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2xLGWk1ySfab"
   },
   "outputs": [],
   "source": [
    "def toTensor(vocab, sentence):\n",
    "    indices = [vocab.word2index[word] for word in sentence.split(' ')]\n",
    "    indices.append(vocab.word2index['EOS'])\n",
    "    return torch.Tensor(indices).long().to(device).view(-1, 1)\n",
    "\n",
    "def getPairs(df):\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "      question, answer = getSentence(df.iloc[i, 0]), getSentence(df.iloc[i, 1])\n",
    "      pairs.append([question, answer])\n",
    "    return pairs\n",
    "      \n",
    "    #temp1 = df[\"Questions\"].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    #temp2 = df[\"Answers\"].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    #return [list(i) for i in zip(temp1, temp2)]\n",
    "\n",
    "def getSentence(sentence):\n",
    "    split = sentence.split()\n",
    "    newSentence = \"\"\n",
    "    for i in range(len(split)):\n",
    "      for x in range(len(split[i])):\n",
    "        if (i == len(split) - 1 and x == len(split[i]) - 1):\n",
    "          newSentence += split[i][x]\n",
    "        else:\n",
    "          newSentence += split[i][x] + \" \"\n",
    "      if (i != len(split) - 1):\n",
    "        newSentence += \"EOW \"\n",
    "    return newSentence\n",
    "\n",
    "def getMaxLen(pairs):\n",
    "    max_src = 0 \n",
    "    max_trg = 0\n",
    "    \n",
    "    for p in pairs:\n",
    "        max_src = len(p[0].split()) if len(p[0].split()) > max_src else max_src\n",
    "        max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\n",
    "        \n",
    "    return max_src, max_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U0JX9s0VSfab"
   },
   "outputs": [],
   "source": [
    "train_pairs = getPairs(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwDg_mYuSfac",
    "outputId": "38f16c37-febc-48a4-cf27-46c1d70d4350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['w h e n EOW d i d EOW b e y o n c e EOW s t a r t EOW b e c o m i n g EOW p o p u l a r',\n",
       "  'i n EOW t h e EOW l a t e EOW 1 9 9 0 s'],\n",
       " ['w h a t EOW a r e a s EOW d i d EOW b e y o n c e EOW c o m p e t e EOW i n EOW w h e n EOW s h e EOW w a s EOW g r o w i n g EOW u p',\n",
       "  's i n g i n g EOW a n d EOW d a n c i n g'],\n",
       " ['w h e n EOW d i d EOW b e y o n c e EOW l e a v e EOW d e s t i n y s EOW c h i l d EOW a n d EOW b e c o m e EOW a EOW s o l o EOW s i n g e r',\n",
       "  '2 0 0 3'],\n",
       " ['i n EOW w h a t EOW c i t y EOW a n d EOW s t a t e EOW d i d EOW b e y o n c e EOW g r o w EOW u p',\n",
       "  'h o u s t o n EOW t e x a s'],\n",
       " ['i n EOW w h i c h EOW d e c a d e EOW d i d EOW b e y o n c e EOW b e c o m e EOW f a m o u s',\n",
       "  'l a t e EOW 1 9 9 0 s']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xOUvIneESfac"
   },
   "outputs": [],
   "source": [
    "Q_vocab = Vocab()\n",
    "A_vocab = Vocab()\n",
    "\n",
    "for pair in train_pairs:\n",
    "    Q_vocab.addSentence(pair[0])\n",
    "    A_vocab.addSentence(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Hyxaqpv0Sfac"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pr_ZAoiKSfac"
   },
   "outputs": [],
   "source": [
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in train_pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in train_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RbogJ-DgSfac"
   },
   "outputs": [],
   "source": [
    "max_src, max_trg = getMaxLen(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yywLFHo1Ega7",
    "outputId": "143f1cc4-0173-4744-8bbd-a6b0e79abdb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RS_z6vXSfac",
    "outputId": "9d59f4ce-99e3-449d-a6e3-1a3fb50b67ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5],\n",
       "        [ 0],\n",
       "        [ 6],\n",
       "        [ 7],\n",
       "        [ 6],\n",
       "        [ 0],\n",
       "        [ 8],\n",
       "        [ 4],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [ 5],\n",
       "        [11],\n",
       "        [ 4],\n",
       "        [ 0],\n",
       "        [12],\n",
       "        [13],\n",
       "        [14],\n",
       "        [15],\n",
       "        [13],\n",
       "        [ 0],\n",
       "        [ 8],\n",
       "        [ 4],\n",
       "        [11],\n",
       "        [10],\n",
       "        [16],\n",
       "        [ 7],\n",
       "        [ 5],\n",
       "        [17],\n",
       "        [ 0],\n",
       "        [18],\n",
       "        [10],\n",
       "        [18],\n",
       "        [19],\n",
       "        [20],\n",
       "        [14],\n",
       "        [15],\n",
       "        [ 1]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3ta8yF2TnDo",
    "outputId": "09fd53cc-d146-4fbd-cd29-cd9b981096bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 3],\n",
       "        [ 0],\n",
       "        [ 4],\n",
       "        [ 5],\n",
       "        [ 6],\n",
       "        [ 0],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 0],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12],\n",
       "        [ 1]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGw1HqWPSfac",
    "outputId": "5f9a9f1e-abeb-46ee-f70a-ee7e32ae01c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fdgzvPRTUPbt"
   },
   "outputs": [],
   "source": [
    "def evaluate(tensor, model):\n",
    "    model.eval()\n",
    "    outputs = model(tensor)\n",
    "    output_text = [A_vocab.index2word[idx] for idx in outputs]\n",
    "    output_sentence = \"\"\n",
    "    for string in output_text:\n",
    "      if (string == \"EOW\"):\n",
    "        output_sentence += \" \"\n",
    "      elif (string == \"EOS\"):\n",
    "        output_sentence += \".\"\n",
    "      else:\n",
    "        output_sentence += string\n",
    "    #output_sentence = ' '.join(output_text)\n",
    "    return output_sentence, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-0V3Y6TVSfac"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_prob = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(self.emb_dim, self.emb_dim, self.num_layers, dropout=self.dropout_prob, bidirectional=True)\n",
    "        self.dropout_layer = nn.Dropout(self.dropout_prob)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*2, batch_size, self.emb_dim).to(device)\n",
    "        cell = torch.zeros(self.num_layers*2, batch_size, self.emb_dim).to(device)\n",
    "        return hidden, cell\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        x = self.dropout_layer(self.embedding(x))\n",
    "        x, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        return x, hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_prob = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, self.num_layers, dropout=self.dropout_prob, bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim*2, self.output_dim)\n",
    "        self.dropout_layer = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = self.dropout_layer(self.embedding(x))\n",
    "        x, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        x = self.dropout_layer(self.fc(x.squeeze(0)))\n",
    "        return x, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_prob = dropout\n",
    "\n",
    "        self.encoder = Encoder(self.input_dim, self.hidden_dim, self.num_layers, self.dropout_prob).to(device)\n",
    "        self.decoder = Decoder(self.output_dim, self.hidden_dim, self.num_layers, self.dropout_prob).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, src, trg=None, teacher_forcing_ratio=0.5):\n",
    "        self.batch_size = src.shape[1]\n",
    "        self.trg_vocab_size = self.output_dim\n",
    "        if (trg != None):\n",
    "          self.trg_len = trg.shape[0]\n",
    "\n",
    "          outputs = torch.zeros(self.trg_len, self.batch_size, self.trg_vocab_size).to(device)\n",
    "          best_guesses = []\n",
    "\n",
    "          hidden, cell = self.encoder.init_hidden(self.batch_size)\n",
    "        \n",
    "          for i in range(src.shape[0]):\n",
    "              _, hidden, cell = self.encoder(src[i], hidden, cell)\n",
    "            \n",
    "          x = torch.zeros(1, self.batch_size, dtype=torch.long, device=device)\n",
    "        \n",
    "          for t in range(0, self.trg_len):\n",
    "              output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "              outputs[t] = output\n",
    "              best_guess = output.argmax(1)\n",
    "              best_guesses.append(best_guess.item())\n",
    "              x = trg[t].unsqueeze(0) if random.random() < teacher_forcing_ratio else best_guess.unsqueeze(0)\n",
    "        \n",
    "          return outputs, best_guesses\n",
    "\n",
    "        else:\n",
    "          outputs = []\n",
    "          hidden, cell = self.encoder.init_hidden(self.batch_size)\n",
    "\n",
    "          for i in range(src.shape[0]):\n",
    "            _, hidden, cell = self.encoder(src[i], hidden, cell)\n",
    "          \n",
    "          x = torch.zeros(1, self.batch_size, dtype=torch.long, device=device)\n",
    "\n",
    "          counts = 0\n",
    "          while x != A_vocab.word2index[\"EOS\"] and counts < max_trg:\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            best_guess = output.argmax(1)\n",
    "            outputs.append(best_guess.item())\n",
    "            x = best_guess.unsqueeze(0)\n",
    "            counts += 1\n",
    "          \n",
    "          return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "s8q6y3hvSfad"
   },
   "outputs": [],
   "source": [
    "input_dim = Q_vocab.n_words\n",
    "output_dim = A_vocab.n_words\n",
    "trg_vocab_size = A_vocab.n_words\n",
    "hidden_dim = 1024\n",
    "dropout = 0.0\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfFJCcLsSfad",
    "outputId": "dfb4dfb7-5429-420a-c3fb-3dcd4a575ff0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdQ0OxSOSfad",
    "outputId": "c584602a-d537-4ba5-9768-d641515197ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f6842031fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tgbATJD6Sfad"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(input_dim, output_dim, hidden_dim, 2, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "U14b14rrSfad"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yONJpAAvU7DM"
   },
   "outputs": [],
   "source": [
    "sentence, output_tensor = evaluate(source_data[0], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-GYhSW9U_Sl",
    "outputId": "2439d111-3dff-4ac8-c57d-13b3b1efcfd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp22yyyyyyyyy2yyyyyyyyy2yyyyyyyyy2yyyyyyy.\n",
      "[33, 33, 16, 16, 21, 21, 21, 21, 21, 21, 21, 21, 21, 16, 21, 21, 21, 21, 21, 21, 21, 21, 21, 16, 21, 21, 21, 21, 21, 21, 21, 21, 21, 16, 21, 21, 21, 21, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "E64-b1sLSfad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 | Training Loss: 3.535\n",
      "Epoch 2/60 | Training Loss: 3.249\n",
      "Epoch 3/60 | Training Loss: 3.109\n",
      "Epoch 4/60 | Training Loss: 2.911\n",
      "Epoch 5/60 | Training Loss: 2.705\n",
      "Epoch 6/60 | Training Loss: 2.609\n",
      "Epoch 7/60 | Training Loss: 2.474\n",
      "Epoch 8/60 | Training Loss: 2.389\n",
      "Epoch 9/60 | Training Loss: 2.163\n",
      "Epoch 10/60 | Training Loss: 2.058\n",
      "Epoch 11/60 | Training Loss: 1.865\n",
      "Epoch 12/60 | Training Loss: 1.736\n",
      "Epoch 13/60 | Training Loss: 1.543\n",
      "Epoch 14/60 | Training Loss: 1.401\n",
      "Epoch 15/60 | Training Loss: 1.291\n",
      "Epoch 16/60 | Training Loss: 1.093\n",
      "Epoch 17/60 | Training Loss: 0.974\n",
      "Epoch 18/60 | Training Loss: 0.851\n",
      "Epoch 19/60 | Training Loss: 0.752\n",
      "Epoch 20/60 | Training Loss: 0.634\n",
      "Epoch 21/60 | Training Loss: 0.586\n",
      "Epoch 22/60 | Training Loss: 0.531\n",
      "Epoch 23/60 | Training Loss: 0.446\n",
      "Epoch 24/60 | Training Loss: 0.427\n",
      "Epoch 25/60 | Training Loss: 0.409\n",
      "Epoch 26/60 | Training Loss: 0.387\n",
      "Epoch 27/60 | Training Loss: 0.355\n",
      "Epoch 28/60 | Training Loss: 0.371\n",
      "Epoch 29/60 | Training Loss: 0.337\n",
      "Epoch 30/60 | Training Loss: 0.324\n",
      "Epoch 31/60 | Training Loss: 0.294\n",
      "Epoch 32/60 | Training Loss: 0.265\n",
      "Epoch 33/60 | Training Loss: 0.275\n",
      "Epoch 34/60 | Training Loss: 0.261\n",
      "Epoch 35/60 | Training Loss: 0.246\n",
      "Epoch 36/60 | Training Loss: 0.218\n",
      "Epoch 37/60 | Training Loss: 0.203\n",
      "Epoch 38/60 | Training Loss: 0.195\n",
      "Epoch 39/60 | Training Loss: 0.189\n",
      "Epoch 40/60 | Training Loss: 0.168\n",
      "Epoch 41/60 | Training Loss: 0.154\n",
      "Epoch 42/60 | Training Loss: 0.171\n",
      "Epoch 43/60 | Training Loss: 0.167\n",
      "Epoch 44/60 | Training Loss: 0.146\n",
      "Epoch 45/60 | Training Loss: 0.165\n",
      "Epoch 46/60 | Training Loss: 0.152\n",
      "Epoch 47/60 | Training Loss: 0.141\n",
      "Epoch 48/60 | Training Loss: 0.148\n",
      "Epoch 49/60 | Training Loss: 0.139\n",
      "Epoch 50/60 | Training Loss: 0.137\n",
      "Epoch 51/60 | Training Loss: 0.142\n",
      "Epoch 52/60 | Training Loss: 0.135\n",
      "Epoch 53/60 | Training Loss: 0.129\n",
      "Epoch 54/60 | Training Loss: 0.128\n",
      "Epoch 55/60 | Training Loss: 0.133\n",
      "Epoch 56/60 | Training Loss: 0.136\n",
      "Epoch 57/60 | Training Loss: 0.128\n",
      "Epoch 58/60 | Training Loss: 0.127\n",
      "Epoch 59/60 | Training Loss: 0.137\n",
      "Epoch 60/60 | Training Loss: 0.131\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "total = 0\n",
    "loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for i in range(len(source_data)):\n",
    "        src = source_data[i].to(device)\n",
    "        trg = target_data[i].to(device)\n",
    "        output, lists = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        current = criterion(output, trg)\n",
    "        loss += current\n",
    "        total += current\n",
    "        if (i + 1) % batch_size == 0 or i == (len(source_data)-1):\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            \n",
    "    print_loss = total / len(source_data)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | Training Loss: {print_loss:.3f}\")\n",
    "    total = 0\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "      learning_rate = learning_rate / 10\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LEtfpU4FSfad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethan: Hi, I'm Ethan, a Q&A chatbot created by Arnav Balaji. Enter 'exit' to quit. What can I answer for you?\n",
      "You: when did beyonce start becoming popular\n",
      "\n",
      "Ethan: nn the late 1990s.\n",
      "You: what album made beyonce a worldwide known artist\n",
      "\n",
      "Ethan: aangerously in love.\n",
      "You: how did beyonce describe herself as a feminist\n",
      "\n",
      "Ethan: oodernday feminist.\n",
      "You: charlies angels featured which single from the band members\n",
      "\n",
      "Ethan: nndependent women part me.\n",
      "You: who was blamed for luckett and roberson leaving destinys child\n",
      "\n",
      "Ethan: eeyonc√©.\n",
      "You: 12ur93e48rf8 &&AWE**(\n",
      "\n",
      "Ethan: Sorry! I don't understand what you are saying! Please ask me something different.\n",
      "You: who is beyonce\n",
      "\n",
      "Ethan: 000.\n",
      "You: exit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = input(\"Ethan: Hi, I'm Ethan, a Q&A chatbot created by Arnav Balaji. Enter 'exit' to quit. What can I answer for you?\\nYou: \")\n",
    "print()\n",
    "while True:\n",
    "    if (sentence.lower() == 'exit'):\n",
    "            break\n",
    "    try:\n",
    "        tokens = prepare_text(sentence)\n",
    "        tokens = getSentence(tokens)\n",
    "        tensor = toTensor(Q_vocab, tokens)\n",
    "        output, output_tensor = evaluate(tensor, model)\n",
    "        sentence = input(\"Ethan: \" + output + \"\\nYou: \")\n",
    "        print()\n",
    "    except: \n",
    "        sentence = input(\"Ethan: Sorry! I don't understand what you are saying! Please ask me something different.\\nYou: \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
